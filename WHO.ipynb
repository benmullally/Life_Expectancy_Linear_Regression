{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aac95ca",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression on WHO Life Expectancy Data\n",
    "\n",
    "Aim is to make a model that can predict life expectancy of a country based on other WHO health data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99e86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0eb1f2",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9053d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Life expectancy   Adult Mortality  infant deaths  Alcohol  \\\n",
      "0               65.0            263.0             62     0.01   \n",
      "16              77.8             74.0              0     4.60   \n",
      "32              75.6             19.0             21      NaN   \n",
      "48              52.4            335.0             66      NaN   \n",
      "64              76.4             13.0              0      NaN   \n",
      "\n",
      "    percentage expenditure  Hepatitis B  Measles    BMI   under-five deaths   \\\n",
      "0                71.279624         65.0      1154   19.1                  83   \n",
      "16              364.975229         99.0         0   58.0                   0   \n",
      "32                0.000000         95.0        63   59.5                  24   \n",
      "48                0.000000         64.0       118   23.3                  98   \n",
      "64                0.000000         99.0         0   47.7                   0   \n",
      "\n",
      "    Polio  ...  Diphtheria    HIV/AIDS           GDP  Population  \\\n",
      "0     6.0  ...         65.0        0.1    584.259210  33736494.0   \n",
      "16   99.0  ...         99.0        0.1   3954.227830     28873.0   \n",
      "32   95.0  ...         95.0        0.1   4132.762920  39871528.0   \n",
      "48    7.0  ...         64.0        1.9   3695.793748   2785935.0   \n",
      "64   86.0  ...         99.0        0.2  13566.954100         NaN   \n",
      "\n",
      "     thinness  1-19 years   thinness 5-9 years  \\\n",
      "0                    17.2                 17.3   \n",
      "16                    1.2                  1.3   \n",
      "32                    6.0                  5.8   \n",
      "48                    8.3                  8.2   \n",
      "64                    3.3                  3.3   \n",
      "\n",
      "    Income composition of resources  Schooling  Status_Developed  \\\n",
      "0                             0.479       10.1                 0   \n",
      "16                            0.762       14.2                 0   \n",
      "32                            0.743       14.4                 0   \n",
      "48                            0.531       11.4                 0   \n",
      "64                            0.784       13.9                 0   \n",
      "\n",
      "    Status_Developing  \n",
      "0                   1  \n",
      "16                  1  \n",
      "32                  1  \n",
      "48                  1  \n",
      "64                  1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Life Expectancy Data.csv\")\n",
    "df = df[df['Year']==2015]\n",
    "df = df.drop(['Country','Year'], axis=1)\n",
    "df = pd.get_dummies(df, columns=['Status'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0465a69",
   "metadata": {},
   "source": [
    "Create dummy variables for categorical data and drop irrelevant columns.\n",
    "\n",
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.iloc[:, 1:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc60126",
   "metadata": {},
   "source": [
    "Visualise correlation between variables and get a rough idea of how they are linked. Lots of linear correlation so linear regression is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd36793",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df.corr().abs()\n",
    "#Correlation Matrix in full\n",
    "f, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f70b80",
   "metadata": {},
   "source": [
    "Correlation matrix of remaining variables. Can see outlier in Total Expenditure so needs further investigation. Can see some highly correlated variables so may need to deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print()\n",
    "print('Number of NA values in Total Expenditure: ')\n",
    "print((df['Total expenditure'].isna().sum()))\n",
    "print()\n",
    "print('Number of NA values in Alcohol: ')\n",
    "print((df['Alcohol'].isna().sum()))\n",
    "#mostly NA values so remove\n",
    "df=df.drop(['Total expenditure'], axis=1)\n",
    "#same for alcohol so drop\n",
    "df=df.drop(['Alcohol'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61a01c",
   "metadata": {},
   "source": [
    "181 of 183 rows contain null values for Total Expenditure and 177 for Alcohol so simply remove these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c02192",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df.drop(['Life expectancy '],axis=1).corr().abs()\n",
    "#Correlation Matrix in full\n",
    "f, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec859131",
   "metadata": {},
   "source": [
    "New correlation matrix- much less highly correlated features. Still needs analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_tri = corrmat.where(np.triu(np.ones(corrmat.shape), k=1).astype(bool))\n",
    "corr_list = upper_tri.stack().sort_values(ascending=False)\n",
    "print('Highest correlated features:')\n",
    "print()\n",
    "print(corr_list.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c67580",
   "metadata": {},
   "source": [
    "Drop any columns that have very high correlation with others (have no effect on model due to repeat data so drop to help dimensionality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "print('Features to drop:'); \n",
    "print(to_drop)\n",
    "df = df.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082b05b",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Run linear regression on several cases of dealing with null values\n",
    "\n",
    "### 1. Delete rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "column_names = df.columns\n",
    "updated_df1 = df.dropna(axis=0)\n",
    "\n",
    "#scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "updated_df1 = scaler.fit_transform(updated_df1)\n",
    "updated_df1 =pd.DataFrame(updated_df1, columns=column_names)\n",
    "\n",
    "y1 = updated_df1['Life expectancy ']\n",
    "updated_df1 = updated_df1.drop(['Life expectancy '], axis=1)\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(updated_df1,y1,test_size=0.3, random_state=2)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Mean absolute error: {mae:.2f}')\n",
    "print(f'Mean squared error: {mse:.2f}')\n",
    "print(f'Root mean squared error: {rmse:.2f}')\n",
    "print(f'R^2 on train data: {lr.score(X_train, y_train)}')\n",
    "print(f'R^2 on test data: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8e8ae",
   "metadata": {},
   "source": [
    "Good generalisation, 79.6% of data predicted accurately. Very low errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439df1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred, ci=None, color=\"g\", marker='+')\n",
    "plt.ylabel('Predicted Life Expectancy')\n",
    "plt.title('True vs Predicted Life Expectancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f711039",
   "metadata": {},
   "source": [
    "### 2. Fill na's with mean of column if continuous and mode if categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df2 = df\n",
    "for column in updated_df2.columns:\n",
    "    if ((column == 'Status_Developed') or (column == 'Status_Developing')):\n",
    "        updated_df2[column]=updated_df2[column].fillna(updated_df2[column].mode())\n",
    "    else:\n",
    "        updated_df2[column]=updated_df2[column].fillna(updated_df2[column].mean())\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "updated_df2 = scaler.fit_transform(updated_df2)\n",
    "updated_df2 =pd.DataFrame(updated_df2, columns=column_names)\n",
    "y1 = updated_df2['Life expectancy ']\n",
    "updated_df2 = updated_df2.drop(['Life expectancy '], axis=1)\n",
    "X_train, X_test,y_train,y_test = train_test_split(updated_df2,y1,test_size=0.3, random_state=2)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Mean absolute error: {mae:.2f}')\n",
    "print(f'Mean squared error: {mse:.2f}')\n",
    "print(f'Root mean squared error: {rmse:.2f}')\n",
    "print(f'R^2 on train data: {lr.score(X_train, y_train)}')\n",
    "print(f'R^2 on test data: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8255669",
   "metadata": {},
   "source": [
    "Pretty good! Explains roughly 86% of new data so generalises well. Very low errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred, ci=None, color=\"g\", marker='+')\n",
    "plt.ylabel('Predicted Life Expectancy')\n",
    "plt.title('True vs Predicted Life Expectancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3c960",
   "metadata": {},
   "source": [
    "### 3. Imputation with additional columns so model knows if data comes from actual data or imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e11b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df3 = df\n",
    "scaler = MinMaxScaler() \n",
    "updated_df3 = scaler.fit_transform(updated_df3)\n",
    "updated_df3 = pd.DataFrame(updated_df3, columns=column_names)\n",
    "y1 = updated_df3['Life expectancy ']\n",
    "updated_df3 = updated_df3.drop(['Life expectancy '], axis=1)\n",
    "for column in updated_df3.columns:\n",
    "    updated_df3[column+'_ismissing'] = updated_df3[column].isnull()\n",
    "    \n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer(strategy = 'mean')\n",
    "updated_df3 = my_imputer.fit_transform(updated_df3)\n",
    "#print(updated_df3.info())\n",
    "X_train, X_test,y_train,y_test = train_test_split(updated_df3,y1,test_size=0.3, random_state=2)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Mean absolute error: {mae:.2f}')\n",
    "print(f'Mean squared error: {mse:.2f}')\n",
    "print(f'Root mean squared error: {rmse:.2f}')\n",
    "print(f'R^2 on train data: {lr.score(X_train, y_train)}')\n",
    "print(f'R^2 on test data: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475d7d7",
   "metadata": {},
   "source": [
    "Exact same evaluation as 2 so not to be chosen due to increased number of variables. Clearly imputation does not affect outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred, ci=None, color=\"g\", marker='+')\n",
    "plt.ylabel('Predicted Life Expectancy')\n",
    "plt.title('True vs Predicted Life Expectancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3826397",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The best multiple linear regression model was produced in 2 by replacing missiing data with mean or mode dependent on the type of data. This produced an R^2 score of 0.86 therefore it predicts the life expectancy of 86% of new countries inputted correctly. This is very accurate and has great generalisability. \n",
    "\n",
    "#### What does this mean?\n",
    "We have found that using multiple linear regression we can predict the life expectancy of a country based upon its other health data from WHO. \n",
    "\n",
    "#### Further ideas?\n",
    "Could try another type of regression model such as Ridge, Lasso or Partial Least Squares (PLS)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
